{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Estate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Problem Statement:\n",
    "\n",
    "A banking institution requires actionable insights from the perspective of Mortgage-Backed Securities, Geographic Business Investment and Real Estate Analysis.\n",
    "\n",
    "The objective is to identify white spaces/potential business in the mortgage loan.\n",
    "\n",
    "The mortgage bank would like to identify potential monthly mortgage expenses for each region based on monthly family income and rental of the real estate.\n",
    "\n",
    "A statistical model needs to be created to predict the potential demand in dollars amount of loan for each of the region in the USA. Also, there is a need to create a dashboard which would refresh periodically post data retrieval from the agencies. This would help to monitor the key metrics and trends.\n",
    "\n",
    "The dashboard must demonstrate relationships and trends for the key metrics as follows: number of loans, average rental income, monthly mortgage and owner’s cost, family income vs mortgage cost comparison across different regions. The metrics are described not to limit the dashboard to these few only.\n",
    "\n",
    "Dataset Description :-\n",
    "\n",
    "Following are the themes the fields fall under Home Owner Costs: Sum of utilities, property taxes.\n",
    "\n",
    "1. Second Mortgage: Households with a second mortgage statistics.\n",
    "\n",
    "2. Home Equity Loan: Households with a Home equity Loan statistics.\n",
    "\n",
    "3. Debt: Households with any type of debt statistics.\n",
    "\n",
    "4. Mortgage Costs: Statistics regarding mortgage payments, home equity loans, utilities and property taxes\n",
    "\n",
    "5. Home Owner Costs: Sum of utilities, property taxes statistics\n",
    "\n",
    "6. Gross Rent: Contract rent plus the estimated average monthly cost of utility features\n",
    "\n",
    "7. Gross Rent as Percent of Income Gross rent as the percent of income very interesting\n",
    "\n",
    "8. High school Graduation: High school graduation statistics.\n",
    "\n",
    "9. Population Demographics: Population demographic statistics.\n",
    "\n",
    "10. Age Demographics: Age demographic statistics.\n",
    "\n",
    "11.Household Income: Total income of people residing in the household.\n",
    "\n",
    "12.Family Income: Total income of people related to the householder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time          #provide a man ways to represent a time\n",
    "import random        # used to generates random no \n",
    "from math import *   # provides access to mathematical functions defiened by the C standards\n",
    "import operator      # it contain functions that are equailent to python's operators\n",
    "import pandas as pd  # Pandas is the most popular python library that is used for data analysis. \n",
    "import numpy as np   # (Numerical Prthon) Used for working with arrays, also has functions for working in domain of linear algebra, fourier transform, matrices.\n",
    "\n",
    "# import plotting libraries\n",
    "\n",
    "import matplotlib    # A plotting library for the Python programming language and its numerical mathematics extension NumPy.\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UID', 'BLOCKID', 'SUMLEVEL', 'COUNTYID', 'STATEID', 'state',\n",
       "       'state_ab', 'city', 'place', 'type', 'primary', 'zip_code', 'area_code',\n",
       "       'lat', 'lng', 'ALand', 'AWater', 'pop', 'male_pop', 'female_pop',\n",
       "       'rent_mean', 'rent_median', 'rent_stdev', 'rent_sample_weight',\n",
       "       'rent_samples', 'rent_gt_10', 'rent_gt_15', 'rent_gt_20', 'rent_gt_25',\n",
       "       'rent_gt_30', 'rent_gt_35', 'rent_gt_40', 'rent_gt_50',\n",
       "       'universe_samples', 'used_samples', 'hi_mean', 'hi_median', 'hi_stdev',\n",
       "       'hi_sample_weight', 'hi_samples', 'family_mean', 'family_median',\n",
       "       'family_stdev', 'family_sample_weight', 'family_samples',\n",
       "       'hc_mortgage_mean', 'hc_mortgage_median', 'hc_mortgage_stdev',\n",
       "       'hc_mortgage_sample_weight', 'hc_mortgage_samples', 'hc_mean',\n",
       "       'hc_median', 'hc_stdev', 'hc_samples', 'hc_sample_weight',\n",
       "       'home_equity_second_mortgage', 'second_mortgage', 'home_equity', 'debt',\n",
       "       'second_mortgage_cdf', 'home_equity_cdf', 'debt_cdf', 'hs_degree',\n",
       "       'hs_degree_male', 'hs_degree_female', 'male_age_mean',\n",
       "       'male_age_median', 'male_age_stdev', 'male_age_sample_weight',\n",
       "       'male_age_samples', 'female_age_mean', 'female_age_median',\n",
       "       'female_age_stdev', 'female_age_sample_weight', 'female_age_samples',\n",
       "       'pct_own', 'married', 'married_snp', 'separated', 'divorced'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UID', 'BLOCKID', 'SUMLEVEL', 'COUNTYID', 'STATEID', 'state',\n",
       "       'state_ab', 'city', 'place', 'type', 'primary', 'zip_code', 'area_code',\n",
       "       'lat', 'lng', 'ALand', 'AWater', 'pop', 'male_pop', 'female_pop',\n",
       "       'rent_mean', 'rent_median', 'rent_stdev', 'rent_sample_weight',\n",
       "       'rent_samples', 'rent_gt_10', 'rent_gt_15', 'rent_gt_20', 'rent_gt_25',\n",
       "       'rent_gt_30', 'rent_gt_35', 'rent_gt_40', 'rent_gt_50',\n",
       "       'universe_samples', 'used_samples', 'hi_mean', 'hi_median', 'hi_stdev',\n",
       "       'hi_sample_weight', 'hi_samples', 'family_mean', 'family_median',\n",
       "       'family_stdev', 'family_sample_weight', 'family_samples',\n",
       "       'hc_mortgage_mean', 'hc_mortgage_median', 'hc_mortgage_stdev',\n",
       "       'hc_mortgage_sample_weight', 'hc_mortgage_samples', 'hc_mean',\n",
       "       'hc_median', 'hc_stdev', 'hc_samples', 'hc_sample_weight',\n",
       "       'home_equity_second_mortgage', 'second_mortgage', 'home_equity', 'debt',\n",
       "       'second_mortgage_cdf', 'home_equity_cdf', 'debt_cdf', 'hs_degree',\n",
       "       'hs_degree_male', 'hs_degree_female', 'male_age_mean',\n",
       "       'male_age_median', 'male_age_stdev', 'male_age_sample_weight',\n",
       "       'male_age_samples', 'female_age_mean', 'female_age_median',\n",
       "       'female_age_stdev', 'female_age_sample_weight', 'female_age_samples',\n",
       "       'pct_own', 'married', 'married_snp', 'separated', 'divorced'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find count of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27321, 80)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11709, 80)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>BLOCKID</th>\n",
       "      <th>SUMLEVEL</th>\n",
       "      <th>COUNTYID</th>\n",
       "      <th>STATEID</th>\n",
       "      <th>state</th>\n",
       "      <th>state_ab</th>\n",
       "      <th>city</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>female_age_mean</th>\n",
       "      <th>female_age_median</th>\n",
       "      <th>female_age_stdev</th>\n",
       "      <th>female_age_sample_weight</th>\n",
       "      <th>female_age_samples</th>\n",
       "      <th>pct_own</th>\n",
       "      <th>married</th>\n",
       "      <th>married_snp</th>\n",
       "      <th>separated</th>\n",
       "      <th>divorced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>City</td>\n",
       "      <td>...</td>\n",
       "      <td>44.48629</td>\n",
       "      <td>45.33333</td>\n",
       "      <td>22.51276</td>\n",
       "      <td>685.33845</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>0.79046</td>\n",
       "      <td>0.57851</td>\n",
       "      <td>0.01882</td>\n",
       "      <td>0.01240</td>\n",
       "      <td>0.08770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>18</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "      <td>South Bend</td>\n",
       "      <td>Roseland</td>\n",
       "      <td>City</td>\n",
       "      <td>...</td>\n",
       "      <td>36.48391</td>\n",
       "      <td>37.58333</td>\n",
       "      <td>23.43353</td>\n",
       "      <td>267.23367</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.52483</td>\n",
       "      <td>0.34886</td>\n",
       "      <td>0.01426</td>\n",
       "      <td>0.01426</td>\n",
       "      <td>0.09030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "      <td>Danville</td>\n",
       "      <td>Danville</td>\n",
       "      <td>City</td>\n",
       "      <td>...</td>\n",
       "      <td>42.15810</td>\n",
       "      <td>42.83333</td>\n",
       "      <td>23.94119</td>\n",
       "      <td>707.01963</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>0.85331</td>\n",
       "      <td>0.64745</td>\n",
       "      <td>0.02830</td>\n",
       "      <td>0.01607</td>\n",
       "      <td>0.10657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>72</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Guaynabo</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>47.77526</td>\n",
       "      <td>50.58333</td>\n",
       "      <td>24.32015</td>\n",
       "      <td>362.20193</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>0.65037</td>\n",
       "      <td>0.47257</td>\n",
       "      <td>0.02021</td>\n",
       "      <td>0.02021</td>\n",
       "      <td>0.10106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>161</td>\n",
       "      <td>20</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan City</td>\n",
       "      <td>City</td>\n",
       "      <td>...</td>\n",
       "      <td>24.17693</td>\n",
       "      <td>21.58333</td>\n",
       "      <td>11.10484</td>\n",
       "      <td>1854.48652</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>0.13046</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UID  BLOCKID  SUMLEVEL  COUNTYID  STATEID        state state_ab  \\\n",
       "0  267822      NaN       140        53       36     New York       NY   \n",
       "1  246444      NaN       140       141       18      Indiana       IN   \n",
       "2  245683      NaN       140        63       18      Indiana       IN   \n",
       "3  279653      NaN       140       127       72  Puerto Rico       PR   \n",
       "4  247218      NaN       140       161       20       Kansas       KS   \n",
       "\n",
       "         city           place   type  ... female_age_mean  female_age_median  \\\n",
       "0    Hamilton        Hamilton   City  ...        44.48629           45.33333   \n",
       "1  South Bend        Roseland   City  ...        36.48391           37.58333   \n",
       "2    Danville        Danville   City  ...        42.15810           42.83333   \n",
       "3    San Juan        Guaynabo  Urban  ...        47.77526           50.58333   \n",
       "4   Manhattan  Manhattan City   City  ...        24.17693           21.58333   \n",
       "\n",
       "   female_age_stdev  female_age_sample_weight  female_age_samples  pct_own  \\\n",
       "0          22.51276                 685.33845              2618.0  0.79046   \n",
       "1          23.43353                 267.23367              1284.0  0.52483   \n",
       "2          23.94119                 707.01963              3238.0  0.85331   \n",
       "3          24.32015                 362.20193              1559.0  0.65037   \n",
       "4          11.10484                1854.48652              3051.0  0.13046   \n",
       "\n",
       "   married  married_snp  separated  divorced  \n",
       "0  0.57851      0.01882    0.01240   0.08770  \n",
       "1  0.34886      0.01426    0.01426   0.09030  \n",
       "2  0.64745      0.02830    0.01607   0.10657  \n",
       "3  0.47257      0.02021    0.02021   0.10106  \n",
       "4  0.12356      0.00000    0.00000   0.03109  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>BLOCKID</th>\n",
       "      <th>SUMLEVEL</th>\n",
       "      <th>COUNTYID</th>\n",
       "      <th>STATEID</th>\n",
       "      <th>state</th>\n",
       "      <th>state_ab</th>\n",
       "      <th>city</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>female_age_mean</th>\n",
       "      <th>female_age_median</th>\n",
       "      <th>female_age_stdev</th>\n",
       "      <th>female_age_sample_weight</th>\n",
       "      <th>female_age_samples</th>\n",
       "      <th>pct_own</th>\n",
       "      <th>married</th>\n",
       "      <th>married_snp</th>\n",
       "      <th>separated</th>\n",
       "      <th>divorced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>163</td>\n",
       "      <td>26</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>MI</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Dearborn Heights City</td>\n",
       "      <td>CDP</td>\n",
       "      <td>...</td>\n",
       "      <td>34.78682</td>\n",
       "      <td>33.75000</td>\n",
       "      <td>21.58531</td>\n",
       "      <td>416.48097</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>0.70252</td>\n",
       "      <td>0.28217</td>\n",
       "      <td>0.05910</td>\n",
       "      <td>0.03813</td>\n",
       "      <td>0.14299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Maine</td>\n",
       "      <td>ME</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>Auburn City</td>\n",
       "      <td>City</td>\n",
       "      <td>...</td>\n",
       "      <td>44.23451</td>\n",
       "      <td>46.66667</td>\n",
       "      <td>22.37036</td>\n",
       "      <td>532.03505</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>0.85128</td>\n",
       "      <td>0.64221</td>\n",
       "      <td>0.02338</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.13377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pine City</td>\n",
       "      <td>Millerton</td>\n",
       "      <td>Borough</td>\n",
       "      <td>...</td>\n",
       "      <td>41.62426</td>\n",
       "      <td>44.50000</td>\n",
       "      <td>22.86213</td>\n",
       "      <td>453.11959</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>0.81897</td>\n",
       "      <td>0.59961</td>\n",
       "      <td>0.01746</td>\n",
       "      <td>0.01358</td>\n",
       "      <td>0.10026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>231</td>\n",
       "      <td>21</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>KY</td>\n",
       "      <td>Monticello</td>\n",
       "      <td>Monticello City</td>\n",
       "      <td>City</td>\n",
       "      <td>...</td>\n",
       "      <td>44.81200</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>21.03155</td>\n",
       "      <td>263.94320</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>0.84609</td>\n",
       "      <td>0.56953</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.04694</td>\n",
       "      <td>0.12489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>355</td>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>Edroy</td>\n",
       "      <td>Town</td>\n",
       "      <td>...</td>\n",
       "      <td>40.66618</td>\n",
       "      <td>42.66667</td>\n",
       "      <td>21.30900</td>\n",
       "      <td>709.90829</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>0.79077</td>\n",
       "      <td>0.57620</td>\n",
       "      <td>0.01726</td>\n",
       "      <td>0.00588</td>\n",
       "      <td>0.16379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UID  BLOCKID  SUMLEVEL  COUNTYID  STATEID         state state_ab  \\\n",
       "0  255504      NaN       140       163       26      Michigan       MI   \n",
       "1  252676      NaN       140         1       23         Maine       ME   \n",
       "2  276314      NaN       140        15       42  Pennsylvania       PA   \n",
       "3  248614      NaN       140       231       21      Kentucky       KY   \n",
       "4  286865      NaN       140       355       48         Texas       TX   \n",
       "\n",
       "             city                  place     type  ... female_age_mean  \\\n",
       "0         Detroit  Dearborn Heights City      CDP  ...        34.78682   \n",
       "1          Auburn            Auburn City     City  ...        44.23451   \n",
       "2       Pine City              Millerton  Borough  ...        41.62426   \n",
       "3      Monticello        Monticello City     City  ...        44.81200   \n",
       "4  Corpus Christi                  Edroy     Town  ...        40.66618   \n",
       "\n",
       "   female_age_median  female_age_stdev  female_age_sample_weight  \\\n",
       "0           33.75000          21.58531                 416.48097   \n",
       "1           46.66667          22.37036                 532.03505   \n",
       "2           44.50000          22.86213                 453.11959   \n",
       "3           48.00000          21.03155                 263.94320   \n",
       "4           42.66667          21.30900                 709.90829   \n",
       "\n",
       "   female_age_samples  pct_own  married  married_snp  separated  divorced  \n",
       "0              1938.0  0.70252  0.28217      0.05910    0.03813   0.14299  \n",
       "1              1950.0  0.85128  0.64221      0.02338    0.00000   0.13377  \n",
       "2              1879.0  0.81897  0.59961      0.01746    0.01358   0.10026  \n",
       "3              1081.0  0.84609  0.56953      0.05492    0.04694   0.12489  \n",
       "4              2956.0  0.79077  0.57620      0.01726    0.00588   0.16379  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>BLOCKID</th>\n",
       "      <th>SUMLEVEL</th>\n",
       "      <th>COUNTYID</th>\n",
       "      <th>STATEID</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>area_code</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>ALand</th>\n",
       "      <th>...</th>\n",
       "      <th>female_age_mean</th>\n",
       "      <th>female_age_median</th>\n",
       "      <th>female_age_stdev</th>\n",
       "      <th>female_age_sample_weight</th>\n",
       "      <th>female_age_samples</th>\n",
       "      <th>pct_own</th>\n",
       "      <th>married</th>\n",
       "      <th>married_snp</th>\n",
       "      <th>separated</th>\n",
       "      <th>divorced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27321.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27321.0</td>\n",
       "      <td>27321.000000</td>\n",
       "      <td>27321.000000</td>\n",
       "      <td>27321.000000</td>\n",
       "      <td>27321.000000</td>\n",
       "      <td>27321.000000</td>\n",
       "      <td>27321.000000</td>\n",
       "      <td>2.732100e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27053.000000</td>\n",
       "      <td>27130.000000</td>\n",
       "      <td>27130.000000</td>\n",
       "      <td>27130.000000</td>\n",
       "      <td>27130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>257331.996303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>85.646426</td>\n",
       "      <td>28.271806</td>\n",
       "      <td>50081.999524</td>\n",
       "      <td>596.507668</td>\n",
       "      <td>37.508813</td>\n",
       "      <td>-91.288394</td>\n",
       "      <td>1.295106e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>40.319803</td>\n",
       "      <td>40.355099</td>\n",
       "      <td>22.178745</td>\n",
       "      <td>544.238432</td>\n",
       "      <td>2208.761903</td>\n",
       "      <td>0.640434</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.047537</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.100248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21343.859725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.333097</td>\n",
       "      <td>16.392846</td>\n",
       "      <td>29558.115660</td>\n",
       "      <td>232.497482</td>\n",
       "      <td>5.588268</td>\n",
       "      <td>16.343816</td>\n",
       "      <td>1.275531e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.886317</td>\n",
       "      <td>8.039585</td>\n",
       "      <td>2.540257</td>\n",
       "      <td>283.546896</td>\n",
       "      <td>1089.316999</td>\n",
       "      <td>0.226640</td>\n",
       "      <td>0.136860</td>\n",
       "      <td>0.037640</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.049055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>220342.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>17.929085</td>\n",
       "      <td>-165.453872</td>\n",
       "      <td>4.113400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>16.008330</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>0.556780</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>238816.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>26554.000000</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>33.899064</td>\n",
       "      <td>-97.816067</td>\n",
       "      <td>1.799408e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>36.892050</td>\n",
       "      <td>34.916670</td>\n",
       "      <td>21.312135</td>\n",
       "      <td>355.995825</td>\n",
       "      <td>1471.000000</td>\n",
       "      <td>0.502780</td>\n",
       "      <td>0.425102</td>\n",
       "      <td>0.020810</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>257220.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>47715.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>38.755183</td>\n",
       "      <td>-86.554374</td>\n",
       "      <td>4.866940e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>40.373320</td>\n",
       "      <td>40.583330</td>\n",
       "      <td>22.514410</td>\n",
       "      <td>503.643890</td>\n",
       "      <td>2066.000000</td>\n",
       "      <td>0.690840</td>\n",
       "      <td>0.526665</td>\n",
       "      <td>0.038840</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.095205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275818.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>77093.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>41.380606</td>\n",
       "      <td>-79.782503</td>\n",
       "      <td>3.359820e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>43.567120</td>\n",
       "      <td>45.416670</td>\n",
       "      <td>23.575260</td>\n",
       "      <td>680.275055</td>\n",
       "      <td>2772.000000</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.605760</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.027487</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>294334.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>99925.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>67.074018</td>\n",
       "      <td>-65.379332</td>\n",
       "      <td>1.039510e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>79.837390</td>\n",
       "      <td>82.250000</td>\n",
       "      <td>30.241270</td>\n",
       "      <td>6197.995200</td>\n",
       "      <td>27250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UID  BLOCKID  SUMLEVEL      COUNTYID       STATEID  \\\n",
       "count   27321.000000      0.0   27321.0  27321.000000  27321.000000   \n",
       "mean   257331.996303      NaN     140.0     85.646426     28.271806   \n",
       "std     21343.859725      NaN       0.0     98.333097     16.392846   \n",
       "min    220342.000000      NaN     140.0      1.000000      1.000000   \n",
       "25%    238816.000000      NaN     140.0     29.000000     13.000000   \n",
       "50%    257220.000000      NaN     140.0     63.000000     28.000000   \n",
       "75%    275818.000000      NaN     140.0    109.000000     42.000000   \n",
       "max    294334.000000      NaN     140.0    840.000000     72.000000   \n",
       "\n",
       "           zip_code     area_code           lat           lng         ALand  \\\n",
       "count  27321.000000  27321.000000  27321.000000  27321.000000  2.732100e+04   \n",
       "mean   50081.999524    596.507668     37.508813    -91.288394  1.295106e+08   \n",
       "std    29558.115660    232.497482      5.588268     16.343816  1.275531e+09   \n",
       "min      602.000000    201.000000     17.929085   -165.453872  4.113400e+04   \n",
       "25%    26554.000000    405.000000     33.899064    -97.816067  1.799408e+06   \n",
       "50%    47715.000000    614.000000     38.755183    -86.554374  4.866940e+06   \n",
       "75%    77093.000000    801.000000     41.380606    -79.782503  3.359820e+07   \n",
       "max    99925.000000    989.000000     67.074018    -65.379332  1.039510e+11   \n",
       "\n",
       "       ...  female_age_mean  female_age_median  female_age_stdev  \\\n",
       "count  ...     27115.000000       27115.000000      27115.000000   \n",
       "mean   ...        40.319803          40.355099         22.178745   \n",
       "std    ...         5.886317           8.039585          2.540257   \n",
       "min    ...        16.008330          13.250000          0.556780   \n",
       "25%    ...        36.892050          34.916670         21.312135   \n",
       "50%    ...        40.373320          40.583330         22.514410   \n",
       "75%    ...        43.567120          45.416670         23.575260   \n",
       "max    ...        79.837390          82.250000         30.241270   \n",
       "\n",
       "       female_age_sample_weight  female_age_samples       pct_own  \\\n",
       "count              27115.000000        27115.000000  27053.000000   \n",
       "mean                 544.238432         2208.761903      0.640434   \n",
       "std                  283.546896         1089.316999      0.226640   \n",
       "min                    0.664700            2.000000      0.000000   \n",
       "25%                  355.995825         1471.000000      0.502780   \n",
       "50%                  503.643890         2066.000000      0.690840   \n",
       "75%                  680.275055         2772.000000      0.817460   \n",
       "max                 6197.995200        27250.000000      1.000000   \n",
       "\n",
       "            married   married_snp     separated      divorced  \n",
       "count  27130.000000  27130.000000  27130.000000  27130.000000  \n",
       "mean       0.508300      0.047537      0.019089      0.100248  \n",
       "std        0.136860      0.037640      0.020796      0.049055  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.425102      0.020810      0.004530      0.065800  \n",
       "50%        0.526665      0.038840      0.013460      0.095205  \n",
       "75%        0.605760      0.065100      0.027487      0.129000  \n",
       "max        1.000000      0.714290      0.714290      1.000000  \n",
       "\n",
       "[8 rows x 74 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>BLOCKID</th>\n",
       "      <th>SUMLEVEL</th>\n",
       "      <th>COUNTYID</th>\n",
       "      <th>STATEID</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>area_code</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>ALand</th>\n",
       "      <th>...</th>\n",
       "      <th>female_age_mean</th>\n",
       "      <th>female_age_median</th>\n",
       "      <th>female_age_stdev</th>\n",
       "      <th>female_age_sample_weight</th>\n",
       "      <th>female_age_samples</th>\n",
       "      <th>pct_own</th>\n",
       "      <th>married</th>\n",
       "      <th>married_snp</th>\n",
       "      <th>separated</th>\n",
       "      <th>divorced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11709.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11709.0</td>\n",
       "      <td>11709.000000</td>\n",
       "      <td>11709.000000</td>\n",
       "      <td>11709.000000</td>\n",
       "      <td>11709.000000</td>\n",
       "      <td>11709.000000</td>\n",
       "      <td>11709.000000</td>\n",
       "      <td>1.170900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>11613.000000</td>\n",
       "      <td>11613.000000</td>\n",
       "      <td>11613.000000</td>\n",
       "      <td>11613.000000</td>\n",
       "      <td>11613.000000</td>\n",
       "      <td>11587.000000</td>\n",
       "      <td>11625.000000</td>\n",
       "      <td>11625.000000</td>\n",
       "      <td>11625.000000</td>\n",
       "      <td>11625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>257525.004783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>85.710650</td>\n",
       "      <td>28.489196</td>\n",
       "      <td>50123.418396</td>\n",
       "      <td>593.598514</td>\n",
       "      <td>37.405491</td>\n",
       "      <td>-91.340229</td>\n",
       "      <td>1.095500e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>40.111999</td>\n",
       "      <td>40.131864</td>\n",
       "      <td>22.148145</td>\n",
       "      <td>550.411243</td>\n",
       "      <td>2233.003186</td>\n",
       "      <td>0.634194</td>\n",
       "      <td>0.505632</td>\n",
       "      <td>0.047960</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.099191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21466.372658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.304334</td>\n",
       "      <td>16.607262</td>\n",
       "      <td>29775.134038</td>\n",
       "      <td>232.074263</td>\n",
       "      <td>5.625904</td>\n",
       "      <td>16.407818</td>\n",
       "      <td>7.624940e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.851192</td>\n",
       "      <td>7.972026</td>\n",
       "      <td>2.554907</td>\n",
       "      <td>280.992521</td>\n",
       "      <td>1072.017063</td>\n",
       "      <td>0.232232</td>\n",
       "      <td>0.139774</td>\n",
       "      <td>0.038693</td>\n",
       "      <td>0.021428</td>\n",
       "      <td>0.048525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>220336.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>17.965835</td>\n",
       "      <td>-166.770979</td>\n",
       "      <td>8.299000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>15.360240</td>\n",
       "      <td>12.833330</td>\n",
       "      <td>0.737110</td>\n",
       "      <td>0.251910</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>238819.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>25570.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>33.919813</td>\n",
       "      <td>-97.816561</td>\n",
       "      <td>1.718660e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>36.729210</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>21.270920</td>\n",
       "      <td>363.225840</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.422020</td>\n",
       "      <td>0.020890</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.064590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>257651.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>47362.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>38.618092</td>\n",
       "      <td>-86.643344</td>\n",
       "      <td>4.835000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>40.196960</td>\n",
       "      <td>40.333330</td>\n",
       "      <td>22.472990</td>\n",
       "      <td>509.103610</td>\n",
       "      <td>2099.000000</td>\n",
       "      <td>0.687640</td>\n",
       "      <td>0.525270</td>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.094350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>276300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>77406.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>41.232973</td>\n",
       "      <td>-79.697311</td>\n",
       "      <td>3.204540e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>43.496490</td>\n",
       "      <td>45.333330</td>\n",
       "      <td>23.549450</td>\n",
       "      <td>685.883910</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>0.815235</td>\n",
       "      <td>0.605660</td>\n",
       "      <td>0.065340</td>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>294333.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>99929.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>64.804269</td>\n",
       "      <td>-65.695344</td>\n",
       "      <td>5.520166e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>90.107940</td>\n",
       "      <td>90.166670</td>\n",
       "      <td>29.626680</td>\n",
       "      <td>4145.557870</td>\n",
       "      <td>15466.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>0.362750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UID  BLOCKID  SUMLEVEL      COUNTYID       STATEID  \\\n",
       "count   11709.000000      0.0   11709.0  11709.000000  11709.000000   \n",
       "mean   257525.004783      NaN     140.0     85.710650     28.489196   \n",
       "std     21466.372658      NaN       0.0     99.304334     16.607262   \n",
       "min    220336.000000      NaN     140.0      1.000000      1.000000   \n",
       "25%    238819.000000      NaN     140.0     29.000000     13.000000   \n",
       "50%    257651.000000      NaN     140.0     61.000000     28.000000   \n",
       "75%    276300.000000      NaN     140.0    109.000000     42.000000   \n",
       "max    294333.000000      NaN     140.0    810.000000     72.000000   \n",
       "\n",
       "           zip_code     area_code           lat           lng         ALand  \\\n",
       "count  11709.000000  11709.000000  11709.000000  11709.000000  1.170900e+04   \n",
       "mean   50123.418396    593.598514     37.405491    -91.340229  1.095500e+08   \n",
       "std    29775.134038    232.074263      5.625904     16.407818  7.624940e+08   \n",
       "min      601.000000    201.000000     17.965835   -166.770979  8.299000e+03   \n",
       "25%    25570.000000    404.000000     33.919813    -97.816561  1.718660e+06   \n",
       "50%    47362.000000    612.000000     38.618092    -86.643344  4.835000e+06   \n",
       "75%    77406.000000    787.000000     41.232973    -79.697311  3.204540e+07   \n",
       "max    99929.000000    989.000000     64.804269    -65.695344  5.520166e+10   \n",
       "\n",
       "       ...  female_age_mean  female_age_median  female_age_stdev  \\\n",
       "count  ...     11613.000000       11613.000000      11613.000000   \n",
       "mean   ...        40.111999          40.131864         22.148145   \n",
       "std    ...         5.851192           7.972026          2.554907   \n",
       "min    ...        15.360240          12.833330          0.737110   \n",
       "25%    ...        36.729210          34.750000         21.270920   \n",
       "50%    ...        40.196960          40.333330         22.472990   \n",
       "75%    ...        43.496490          45.333330         23.549450   \n",
       "max    ...        90.107940          90.166670         29.626680   \n",
       "\n",
       "       female_age_sample_weight  female_age_samples       pct_own  \\\n",
       "count              11613.000000        11613.000000  11587.000000   \n",
       "mean                 550.411243         2233.003186      0.634194   \n",
       "std                  280.992521         1072.017063      0.232232   \n",
       "min                    0.251910            3.000000      0.000000   \n",
       "25%                  363.225840         1499.000000      0.492500   \n",
       "50%                  509.103610         2099.000000      0.687640   \n",
       "75%                  685.883910         2800.000000      0.815235   \n",
       "max                 4145.557870        15466.000000      1.000000   \n",
       "\n",
       "            married   married_snp     separated      divorced  \n",
       "count  11625.000000  11625.000000  11625.000000  11625.000000  \n",
       "mean       0.505632      0.047960      0.019346      0.099191  \n",
       "std        0.139774      0.038693      0.021428      0.048525  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.422020      0.020890      0.004500      0.064590  \n",
       "50%        0.525270      0.038680      0.013870      0.094350  \n",
       "75%        0.605660      0.065340      0.027910      0.128400  \n",
       "max        1.000000      0.714290      0.714290      0.362750  \n",
       "\n",
       "[8 rows x 74 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27321 entries, 0 to 27320\n",
      "Data columns (total 80 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   UID                          27321 non-null  int64  \n",
      " 1   BLOCKID                      0 non-null      float64\n",
      " 2   SUMLEVEL                     27321 non-null  int64  \n",
      " 3   COUNTYID                     27321 non-null  int64  \n",
      " 4   STATEID                      27321 non-null  int64  \n",
      " 5   state                        27321 non-null  object \n",
      " 6   state_ab                     27321 non-null  object \n",
      " 7   city                         27321 non-null  object \n",
      " 8   place                        27321 non-null  object \n",
      " 9   type                         27321 non-null  object \n",
      " 10  primary                      27321 non-null  object \n",
      " 11  zip_code                     27321 non-null  int64  \n",
      " 12  area_code                    27321 non-null  int64  \n",
      " 13  lat                          27321 non-null  float64\n",
      " 14  lng                          27321 non-null  float64\n",
      " 15  ALand                        27321 non-null  float64\n",
      " 16  AWater                       27321 non-null  int64  \n",
      " 17  pop                          27321 non-null  int64  \n",
      " 18  male_pop                     27321 non-null  int64  \n",
      " 19  female_pop                   27321 non-null  int64  \n",
      " 20  rent_mean                    27007 non-null  float64\n",
      " 21  rent_median                  27007 non-null  float64\n",
      " 22  rent_stdev                   27007 non-null  float64\n",
      " 23  rent_sample_weight           27007 non-null  float64\n",
      " 24  rent_samples                 27007 non-null  float64\n",
      " 25  rent_gt_10                   27007 non-null  float64\n",
      " 26  rent_gt_15                   27007 non-null  float64\n",
      " 27  rent_gt_20                   27007 non-null  float64\n",
      " 28  rent_gt_25                   27007 non-null  float64\n",
      " 29  rent_gt_30                   27007 non-null  float64\n",
      " 30  rent_gt_35                   27007 non-null  float64\n",
      " 31  rent_gt_40                   27007 non-null  float64\n",
      " 32  rent_gt_50                   27007 non-null  float64\n",
      " 33  universe_samples             27321 non-null  int64  \n",
      " 34  used_samples                 27321 non-null  int64  \n",
      " 35  hi_mean                      27053 non-null  float64\n",
      " 36  hi_median                    27053 non-null  float64\n",
      " 37  hi_stdev                     27053 non-null  float64\n",
      " 38  hi_sample_weight             27053 non-null  float64\n",
      " 39  hi_samples                   27053 non-null  float64\n",
      " 40  family_mean                  27023 non-null  float64\n",
      " 41  family_median                27023 non-null  float64\n",
      " 42  family_stdev                 27023 non-null  float64\n",
      " 43  family_sample_weight         27023 non-null  float64\n",
      " 44  family_samples               27023 non-null  float64\n",
      " 45  hc_mortgage_mean             26748 non-null  float64\n",
      " 46  hc_mortgage_median           26748 non-null  float64\n",
      " 47  hc_mortgage_stdev            26748 non-null  float64\n",
      " 48  hc_mortgage_sample_weight    26748 non-null  float64\n",
      " 49  hc_mortgage_samples          26748 non-null  float64\n",
      " 50  hc_mean                      26721 non-null  float64\n",
      " 51  hc_median                    26721 non-null  float64\n",
      " 52  hc_stdev                     26721 non-null  float64\n",
      " 53  hc_samples                   26721 non-null  float64\n",
      " 54  hc_sample_weight             26721 non-null  float64\n",
      " 55  home_equity_second_mortgage  26864 non-null  float64\n",
      " 56  second_mortgage              26864 non-null  float64\n",
      " 57  home_equity                  26864 non-null  float64\n",
      " 58  debt                         26864 non-null  float64\n",
      " 59  second_mortgage_cdf          26864 non-null  float64\n",
      " 60  home_equity_cdf              26864 non-null  float64\n",
      " 61  debt_cdf                     26864 non-null  float64\n",
      " 62  hs_degree                    27131 non-null  float64\n",
      " 63  hs_degree_male               27121 non-null  float64\n",
      " 64  hs_degree_female             27098 non-null  float64\n",
      " 65  male_age_mean                27132 non-null  float64\n",
      " 66  male_age_median              27132 non-null  float64\n",
      " 67  male_age_stdev               27132 non-null  float64\n",
      " 68  male_age_sample_weight       27132 non-null  float64\n",
      " 69  male_age_samples             27132 non-null  float64\n",
      " 70  female_age_mean              27115 non-null  float64\n",
      " 71  female_age_median            27115 non-null  float64\n",
      " 72  female_age_stdev             27115 non-null  float64\n",
      " 73  female_age_sample_weight     27115 non-null  float64\n",
      " 74  female_age_samples           27115 non-null  float64\n",
      " 75  pct_own                      27053 non-null  float64\n",
      " 76  married                      27130 non-null  float64\n",
      " 77  married_snp                  27130 non-null  float64\n",
      " 78  separated                    27130 non-null  float64\n",
      " 79  divorced                     27130 non-null  float64\n",
      "dtypes: float64(62), int64(12), object(6)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11709 entries, 0 to 11708\n",
      "Data columns (total 80 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   UID                          11709 non-null  int64  \n",
      " 1   BLOCKID                      0 non-null      float64\n",
      " 2   SUMLEVEL                     11709 non-null  int64  \n",
      " 3   COUNTYID                     11709 non-null  int64  \n",
      " 4   STATEID                      11709 non-null  int64  \n",
      " 5   state                        11709 non-null  object \n",
      " 6   state_ab                     11709 non-null  object \n",
      " 7   city                         11709 non-null  object \n",
      " 8   place                        11709 non-null  object \n",
      " 9   type                         11709 non-null  object \n",
      " 10  primary                      11709 non-null  object \n",
      " 11  zip_code                     11709 non-null  int64  \n",
      " 12  area_code                    11709 non-null  int64  \n",
      " 13  lat                          11709 non-null  float64\n",
      " 14  lng                          11709 non-null  float64\n",
      " 15  ALand                        11709 non-null  int64  \n",
      " 16  AWater                       11709 non-null  int64  \n",
      " 17  pop                          11709 non-null  int64  \n",
      " 18  male_pop                     11709 non-null  int64  \n",
      " 19  female_pop                   11709 non-null  int64  \n",
      " 20  rent_mean                    11561 non-null  float64\n",
      " 21  rent_median                  11561 non-null  float64\n",
      " 22  rent_stdev                   11561 non-null  float64\n",
      " 23  rent_sample_weight           11561 non-null  float64\n",
      " 24  rent_samples                 11561 non-null  float64\n",
      " 25  rent_gt_10                   11560 non-null  float64\n",
      " 26  rent_gt_15                   11560 non-null  float64\n",
      " 27  rent_gt_20                   11560 non-null  float64\n",
      " 28  rent_gt_25                   11560 non-null  float64\n",
      " 29  rent_gt_30                   11560 non-null  float64\n",
      " 30  rent_gt_35                   11560 non-null  float64\n",
      " 31  rent_gt_40                   11560 non-null  float64\n",
      " 32  rent_gt_50                   11560 non-null  float64\n",
      " 33  universe_samples             11709 non-null  int64  \n",
      " 34  used_samples                 11709 non-null  int64  \n",
      " 35  hi_mean                      11587 non-null  float64\n",
      " 36  hi_median                    11587 non-null  float64\n",
      " 37  hi_stdev                     11587 non-null  float64\n",
      " 38  hi_sample_weight             11587 non-null  float64\n",
      " 39  hi_samples                   11587 non-null  float64\n",
      " 40  family_mean                  11573 non-null  float64\n",
      " 41  family_median                11573 non-null  float64\n",
      " 42  family_stdev                 11573 non-null  float64\n",
      " 43  family_sample_weight         11573 non-null  float64\n",
      " 44  family_samples               11573 non-null  float64\n",
      " 45  hc_mortgage_mean             11441 non-null  float64\n",
      " 46  hc_mortgage_median           11441 non-null  float64\n",
      " 47  hc_mortgage_stdev            11441 non-null  float64\n",
      " 48  hc_mortgage_sample_weight    11441 non-null  float64\n",
      " 49  hc_mortgage_samples          11441 non-null  float64\n",
      " 50  hc_mean                      11419 non-null  float64\n",
      " 51  hc_median                    11419 non-null  float64\n",
      " 52  hc_stdev                     11419 non-null  float64\n",
      " 53  hc_samples                   11419 non-null  float64\n",
      " 54  hc_sample_weight             11419 non-null  float64\n",
      " 55  home_equity_second_mortgage  11489 non-null  float64\n",
      " 56  second_mortgage              11489 non-null  float64\n",
      " 57  home_equity                  11489 non-null  float64\n",
      " 58  debt                         11489 non-null  float64\n",
      " 59  second_mortgage_cdf          11489 non-null  float64\n",
      " 60  home_equity_cdf              11489 non-null  float64\n",
      " 61  debt_cdf                     11489 non-null  float64\n",
      " 62  hs_degree                    11624 non-null  float64\n",
      " 63  hs_degree_male               11620 non-null  float64\n",
      " 64  hs_degree_female             11604 non-null  float64\n",
      " 65  male_age_mean                11625 non-null  float64\n",
      " 66  male_age_median              11625 non-null  float64\n",
      " 67  male_age_stdev               11625 non-null  float64\n",
      " 68  male_age_sample_weight       11625 non-null  float64\n",
      " 69  male_age_samples             11625 non-null  float64\n",
      " 70  female_age_mean              11613 non-null  float64\n",
      " 71  female_age_median            11613 non-null  float64\n",
      " 72  female_age_stdev             11613 non-null  float64\n",
      " 73  female_age_sample_weight     11613 non-null  float64\n",
      " 74  female_age_samples           11613 non-null  float64\n",
      " 75  pct_own                      11587 non-null  float64\n",
      " 76  married                      11625 non-null  float64\n",
      " 77  married_snp                  11625 non-null  float64\n",
      " 78  separated                    11625 non-null  float64\n",
      " 79  divorced                     11625 non-null  float64\n",
      "dtypes: float64(61), int64(13), object(6)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Figure out the primary key and look for the requirement of indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UID is unique userID value in the train and test dataset. So an index can be created from the UID feature\n",
    "df_train.set_index(keys=['UID'],inplace=True) #Set the DataFrame's existing column as an index.\n",
    "df_test.set_index(keys=['UID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLOCKID</th>\n",
       "      <th>SUMLEVEL</th>\n",
       "      <th>COUNTYID</th>\n",
       "      <th>STATEID</th>\n",
       "      <th>state</th>\n",
       "      <th>state_ab</th>\n",
       "      <th>city</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>primary</th>\n",
       "      <th>...</th>\n",
       "      <th>female_age_mean</th>\n",
       "      <th>female_age_median</th>\n",
       "      <th>female_age_stdev</th>\n",
       "      <th>female_age_sample_weight</th>\n",
       "      <th>female_age_samples</th>\n",
       "      <th>pct_own</th>\n",
       "      <th>married</th>\n",
       "      <th>married_snp</th>\n",
       "      <th>separated</th>\n",
       "      <th>divorced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>267822</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>City</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>44.48629</td>\n",
       "      <td>45.33333</td>\n",
       "      <td>22.51276</td>\n",
       "      <td>685.33845</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>0.79046</td>\n",
       "      <td>0.57851</td>\n",
       "      <td>0.01882</td>\n",
       "      <td>0.01240</td>\n",
       "      <td>0.08770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246444</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>18</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "      <td>South Bend</td>\n",
       "      <td>Roseland</td>\n",
       "      <td>City</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>36.48391</td>\n",
       "      <td>37.58333</td>\n",
       "      <td>23.43353</td>\n",
       "      <td>267.23367</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.52483</td>\n",
       "      <td>0.34886</td>\n",
       "      <td>0.01426</td>\n",
       "      <td>0.01426</td>\n",
       "      <td>0.09030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245683</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "      <td>Danville</td>\n",
       "      <td>Danville</td>\n",
       "      <td>City</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>42.15810</td>\n",
       "      <td>42.83333</td>\n",
       "      <td>23.94119</td>\n",
       "      <td>707.01963</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>0.85331</td>\n",
       "      <td>0.64745</td>\n",
       "      <td>0.02830</td>\n",
       "      <td>0.01607</td>\n",
       "      <td>0.10657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279653</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>72</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Guaynabo</td>\n",
       "      <td>Urban</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>47.77526</td>\n",
       "      <td>50.58333</td>\n",
       "      <td>24.32015</td>\n",
       "      <td>362.20193</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>0.65037</td>\n",
       "      <td>0.47257</td>\n",
       "      <td>0.02021</td>\n",
       "      <td>0.02021</td>\n",
       "      <td>0.10106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>161</td>\n",
       "      <td>20</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan City</td>\n",
       "      <td>City</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>24.17693</td>\n",
       "      <td>21.58333</td>\n",
       "      <td>11.10484</td>\n",
       "      <td>1854.48652</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>0.13046</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BLOCKID  SUMLEVEL  COUNTYID  STATEID        state state_ab  \\\n",
       "UID                                                                  \n",
       "267822      NaN       140        53       36     New York       NY   \n",
       "246444      NaN       140       141       18      Indiana       IN   \n",
       "245683      NaN       140        63       18      Indiana       IN   \n",
       "279653      NaN       140       127       72  Puerto Rico       PR   \n",
       "247218      NaN       140       161       20       Kansas       KS   \n",
       "\n",
       "              city           place   type primary  ...  female_age_mean  \\\n",
       "UID                                                ...                    \n",
       "267822    Hamilton        Hamilton   City   tract  ...         44.48629   \n",
       "246444  South Bend        Roseland   City   tract  ...         36.48391   \n",
       "245683    Danville        Danville   City   tract  ...         42.15810   \n",
       "279653    San Juan        Guaynabo  Urban   tract  ...         47.77526   \n",
       "247218   Manhattan  Manhattan City   City   tract  ...         24.17693   \n",
       "\n",
       "        female_age_median  female_age_stdev  female_age_sample_weight  \\\n",
       "UID                                                                     \n",
       "267822           45.33333          22.51276                 685.33845   \n",
       "246444           37.58333          23.43353                 267.23367   \n",
       "245683           42.83333          23.94119                 707.01963   \n",
       "279653           50.58333          24.32015                 362.20193   \n",
       "247218           21.58333          11.10484                1854.48652   \n",
       "\n",
       "        female_age_samples  pct_own  married  married_snp  separated  divorced  \n",
       "UID                                                                             \n",
       "267822              2618.0  0.79046  0.57851      0.01882    0.01240   0.08770  \n",
       "246444              1284.0  0.52483  0.34886      0.01426    0.01426   0.09030  \n",
       "245683              3238.0  0.85331  0.64745      0.02830    0.01607   0.10657  \n",
       "279653              1559.0  0.65037  0.47257      0.02021    0.02021   0.10106  \n",
       "247218              3051.0  0.13046  0.12356      0.00000    0.00000   0.03109  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLOCKID</th>\n",
       "      <th>SUMLEVEL</th>\n",
       "      <th>COUNTYID</th>\n",
       "      <th>STATEID</th>\n",
       "      <th>state</th>\n",
       "      <th>state_ab</th>\n",
       "      <th>city</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>primary</th>\n",
       "      <th>...</th>\n",
       "      <th>female_age_mean</th>\n",
       "      <th>female_age_median</th>\n",
       "      <th>female_age_stdev</th>\n",
       "      <th>female_age_sample_weight</th>\n",
       "      <th>female_age_samples</th>\n",
       "      <th>pct_own</th>\n",
       "      <th>married</th>\n",
       "      <th>married_snp</th>\n",
       "      <th>separated</th>\n",
       "      <th>divorced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255504</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>163</td>\n",
       "      <td>26</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>MI</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Dearborn Heights City</td>\n",
       "      <td>CDP</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>34.78682</td>\n",
       "      <td>33.75000</td>\n",
       "      <td>21.58531</td>\n",
       "      <td>416.48097</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>0.70252</td>\n",
       "      <td>0.28217</td>\n",
       "      <td>0.05910</td>\n",
       "      <td>0.03813</td>\n",
       "      <td>0.14299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252676</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Maine</td>\n",
       "      <td>ME</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>Auburn City</td>\n",
       "      <td>City</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>44.23451</td>\n",
       "      <td>46.66667</td>\n",
       "      <td>22.37036</td>\n",
       "      <td>532.03505</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>0.85128</td>\n",
       "      <td>0.64221</td>\n",
       "      <td>0.02338</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.13377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pine City</td>\n",
       "      <td>Millerton</td>\n",
       "      <td>Borough</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>41.62426</td>\n",
       "      <td>44.50000</td>\n",
       "      <td>22.86213</td>\n",
       "      <td>453.11959</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>0.81897</td>\n",
       "      <td>0.59961</td>\n",
       "      <td>0.01746</td>\n",
       "      <td>0.01358</td>\n",
       "      <td>0.10026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248614</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>231</td>\n",
       "      <td>21</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>KY</td>\n",
       "      <td>Monticello</td>\n",
       "      <td>Monticello City</td>\n",
       "      <td>City</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>44.81200</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>21.03155</td>\n",
       "      <td>263.94320</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>0.84609</td>\n",
       "      <td>0.56953</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.04694</td>\n",
       "      <td>0.12489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286865</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>355</td>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>Edroy</td>\n",
       "      <td>Town</td>\n",
       "      <td>tract</td>\n",
       "      <td>...</td>\n",
       "      <td>40.66618</td>\n",
       "      <td>42.66667</td>\n",
       "      <td>21.30900</td>\n",
       "      <td>709.90829</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>0.79077</td>\n",
       "      <td>0.57620</td>\n",
       "      <td>0.01726</td>\n",
       "      <td>0.00588</td>\n",
       "      <td>0.16379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BLOCKID  SUMLEVEL  COUNTYID  STATEID         state state_ab  \\\n",
       "UID                                                                   \n",
       "255504      NaN       140       163       26      Michigan       MI   \n",
       "252676      NaN       140         1       23         Maine       ME   \n",
       "276314      NaN       140        15       42  Pennsylvania       PA   \n",
       "248614      NaN       140       231       21      Kentucky       KY   \n",
       "286865      NaN       140       355       48         Texas       TX   \n",
       "\n",
       "                  city                  place     type primary  ...  \\\n",
       "UID                                                             ...   \n",
       "255504         Detroit  Dearborn Heights City      CDP   tract  ...   \n",
       "252676          Auburn            Auburn City     City   tract  ...   \n",
       "276314       Pine City              Millerton  Borough   tract  ...   \n",
       "248614      Monticello        Monticello City     City   tract  ...   \n",
       "286865  Corpus Christi                  Edroy     Town   tract  ...   \n",
       "\n",
       "        female_age_mean  female_age_median  female_age_stdev  \\\n",
       "UID                                                            \n",
       "255504         34.78682           33.75000          21.58531   \n",
       "252676         44.23451           46.66667          22.37036   \n",
       "276314         41.62426           44.50000          22.86213   \n",
       "248614         44.81200           48.00000          21.03155   \n",
       "286865         40.66618           42.66667          21.30900   \n",
       "\n",
       "        female_age_sample_weight  female_age_samples  pct_own  married  \\\n",
       "UID                                                                      \n",
       "255504                 416.48097              1938.0  0.70252  0.28217   \n",
       "252676                 532.03505              1950.0  0.85128  0.64221   \n",
       "276314                 453.11959              1879.0  0.81897  0.59961   \n",
       "248614                 263.94320              1081.0  0.84609  0.56953   \n",
       "286865                 709.90829              2956.0  0.79077  0.57620   \n",
       "\n",
       "        married_snp  separated  divorced  \n",
       "UID                                       \n",
       "255504      0.05910    0.03813   0.14299  \n",
       "252676      0.02338    0.00000   0.13377  \n",
       "276314      0.01746    0.01358   0.10026  \n",
       "248614      0.05492    0.04694   0.12489  \n",
       "286865      0.01726    0.00588   0.16379  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gauge the fill rate of the variables and devise plans for missing value treatment. Please explain explicitly the reason for the treatment chosen for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percantage of missing values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLOCKID</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_samples</th>\n",
       "      <td>2.196113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mean</th>\n",
       "      <td>2.196113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_median</th>\n",
       "      <td>2.196113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_stdev</th>\n",
       "      <td>2.196113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_sample_weight</th>\n",
       "      <td>2.196113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_mean</th>\n",
       "      <td>2.097288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_stdev</th>\n",
       "      <td>2.097288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_sample_weight</th>\n",
       "      <td>2.097288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_samples</th>\n",
       "      <td>2.097288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Percantage of missing values\n",
       "BLOCKID                                      100.000000\n",
       "hc_samples                                     2.196113\n",
       "hc_mean                                        2.196113\n",
       "hc_median                                      2.196113\n",
       "hc_stdev                                       2.196113\n",
       "hc_sample_weight                               2.196113\n",
       "hc_mortgage_mean                               2.097288\n",
       "hc_mortgage_stdev                              2.097288\n",
       "hc_mortgage_sample_weight                      2.097288\n",
       "hc_mortgage_samples                            2.097288"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percantage of missing values / null values in train set\n",
    "missing_list_train=df_train.isnull().sum() *100/len(df_train) \n",
    "\n",
    "# adding above variable as a column in a data frame and name the column\n",
    "missing_values_df_train=pd.DataFrame(missing_list_train,columns=['Percantage of missing values'])\n",
    "\n",
    "# sort the data frame based on the above newly added column\n",
    "missing_values_df_train.sort_values(by=['Percantage of missing values'],inplace=True,ascending=False)\n",
    "\n",
    "# display first 10 rows which have missing values\n",
    "missing_values_df_train[missing_values_df_train['Percantage of missing values'] >0][:10]\n",
    "\n",
    "#BLOCKID can be dropped, since it is 100%missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percantage of missing values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLOCKID</th>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_samples</th>\n",
       "      <td>1.061455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mean</th>\n",
       "      <td>1.061455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_median</th>\n",
       "      <td>1.061455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_stdev</th>\n",
       "      <td>1.061455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_sample_weight</th>\n",
       "      <td>1.061455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_mean</th>\n",
       "      <td>0.980930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_stdev</th>\n",
       "      <td>0.980930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_sample_weight</th>\n",
       "      <td>0.980930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_mortgage_samples</th>\n",
       "      <td>0.980930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Percantage of missing values\n",
       "BLOCKID                                       42.857143\n",
       "hc_samples                                     1.061455\n",
       "hc_mean                                        1.061455\n",
       "hc_median                                      1.061455\n",
       "hc_stdev                                       1.061455\n",
       "hc_sample_weight                               1.061455\n",
       "hc_mortgage_mean                               0.980930\n",
       "hc_mortgage_stdev                              0.980930\n",
       "hc_mortgage_sample_weight                      0.980930\n",
       "hc_mortgage_samples                            0.980930"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percantage of missing values / null values in test set\n",
    "missing_list_test=df_test.isnull().sum() *100/len(df_train)\n",
    "\n",
    "# adding above variable as a column in a data frame and name the column\n",
    "missing_values_df_test=pd.DataFrame(missing_list_test,columns=['Percantage of missing values'])\n",
    "\n",
    "# sort the data frame based on the above newly added column\n",
    "missing_values_df_test.sort_values(by=['Percantage of missing values'],inplace=True,ascending=False)\n",
    "\n",
    "# display first 10 rows which have missing values\n",
    "missing_values_df_test[missing_values_df_test['Percantage of missing values'] >0][:10]\n",
    "\n",
    "#BLOCKID can be dropped, since it is 43%missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOCKID column is present\n"
     ]
    }
   ],
   "source": [
    "# Confirm whether the deleted column is present in the dataframe or not\n",
    "\n",
    "if 'BLOCKID' in df_train.columns : \n",
    "  print('BLOCKID column is present') \n",
    "     \n",
    "else: \n",
    "  print('BLOCKID column is not present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['BLOCKID','SUMLEVEL'],inplace=True) #SUMLEVEL doest not have any predictive power and no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns=['BLOCKID','SUMLEVEL'],inplace=True) #SUMLEVEL doest not have any predictive power and no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOCKID column is not present\n"
     ]
    }
   ],
   "source": [
    "# Confirm whether the deleted column is present in the dataframe or not\n",
    "\n",
    "if 'BLOCKID' in df_train.columns : \n",
    "  print('BLOCKID column is present') \n",
    "else: \n",
    "  print('BLOCKID column is not present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rent_mean', 'rent_median', 'rent_stdev', 'rent_sample_weight', 'rent_samples', 'rent_gt_10', 'rent_gt_15', 'rent_gt_20', 'rent_gt_25', 'rent_gt_30', 'rent_gt_35', 'rent_gt_40', 'rent_gt_50', 'hi_mean', 'hi_median', 'hi_stdev', 'hi_sample_weight', 'hi_samples', 'family_mean', 'family_median', 'family_stdev', 'family_sample_weight', 'family_samples', 'hc_mortgage_mean', 'hc_mortgage_median', 'hc_mortgage_stdev', 'hc_mortgage_sample_weight', 'hc_mortgage_samples', 'hc_mean', 'hc_median', 'hc_stdev', 'hc_samples', 'hc_sample_weight', 'home_equity_second_mortgage', 'second_mortgage', 'home_equity', 'debt', 'second_mortgage_cdf', 'home_equity_cdf', 'debt_cdf', 'hs_degree', 'hs_degree_male', 'hs_degree_female', 'male_age_mean', 'male_age_median', 'male_age_stdev', 'male_age_sample_weight', 'male_age_samples', 'female_age_mean', 'female_age_median', 'female_age_stdev', 'female_age_sample_weight', 'female_age_samples', 'pct_own', 'married', 'married_snp', 'separated', 'divorced']\n"
     ]
    }
   ],
   "source": [
    "# Imputing  missing values with mean\n",
    "\n",
    "missing_train_cols=[]\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].isna().sum() !=0:\n",
    "         missing_train_cols.append(col)\n",
    "print(missing_train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rent_mean', 'rent_median', 'rent_stdev', 'rent_sample_weight', 'rent_samples', 'rent_gt_10', 'rent_gt_15', 'rent_gt_20', 'rent_gt_25', 'rent_gt_30', 'rent_gt_35', 'rent_gt_40', 'rent_gt_50', 'hi_mean', 'hi_median', 'hi_stdev', 'hi_sample_weight', 'hi_samples', 'family_mean', 'family_median', 'family_stdev', 'family_sample_weight', 'family_samples', 'hc_mortgage_mean', 'hc_mortgage_median', 'hc_mortgage_stdev', 'hc_mortgage_sample_weight', 'hc_mortgage_samples', 'hc_mean', 'hc_median', 'hc_stdev', 'hc_samples', 'hc_sample_weight', 'home_equity_second_mortgage', 'second_mortgage', 'home_equity', 'debt', 'second_mortgage_cdf', 'home_equity_cdf', 'debt_cdf', 'hs_degree', 'hs_degree_male', 'hs_degree_female', 'male_age_mean', 'male_age_median', 'male_age_stdev', 'male_age_sample_weight', 'male_age_samples', 'female_age_mean', 'female_age_median', 'female_age_stdev', 'female_age_sample_weight', 'female_age_samples', 'pct_own', 'married', 'married_snp', 'separated', 'divorced']\n"
     ]
    }
   ],
   "source": [
    "# Imputing  missing values with mean\n",
    "\n",
    "missing_test_cols=[]\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].isna().sum() !=0:\n",
    "         missing_test_cols.append(col)            \n",
    "print(missing_test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing cols are all numerical variables\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if col in (missing_train_cols):\n",
    "        df_train[col].replace(np.nan, df_train[col].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing cols are all numerical variables\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if col in (missing_test_cols):\n",
    "        df_test[col].replace(np.nan, df_test[col].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA):\n",
    "\n",
    "### Perform debt analysis. You may take the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Explore the top 2,500 locations where the percentage of households with a second mortgage is the highest and percent ownership is above 10 percent. Visualize using geo-map. You may keep the upper limit for the percent of households with a second mortgage to 50 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasql import sqldf\n",
    "\n",
    "q1 = \"select place,pct_own,second_mortgage,lat,lng from df_train where pct_own >0.10 and second_mortgage <0.5 order by second_mortgage DESC LIMIT 2500;\"\n",
    "\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "df_train_location_mort_pct=pysqldf(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_location_mort_pct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scattergeo(\n",
    "    lat = df_train_location_mort_pct['lat'],\n",
    "    lon = df_train_location_mort_pct['lng']),\n",
    "    )\n",
    "fig.update_layout(\n",
    "    geo=dict(\n",
    "        scope = 'north america',\n",
    "        showland = True,\n",
    "        landcolor = \"rgb(212, 212, 212)\",\n",
    "        subunitcolor = \"rgb(255, 255, 255)\",\n",
    "        countrycolor = \"rgb(255, 255, 255)\",\n",
    "        showlakes = True,\n",
    "        lakecolor = \"rgb(255, 255, 255)\",\n",
    "        showsubunits = True,\n",
    "        showcountries = True,\n",
    "        resolution = 50,\n",
    "        projection = dict(\n",
    "            type = 'conic conformal',\n",
    "            rotation_lon = -100\n",
    "        ),\n",
    "        lonaxis = dict(\n",
    "            showgrid = True,\n",
    "            gridwidth = 0.5,\n",
    "            range= [ -140.0, -55.0 ],\n",
    "            dtick = 5\n",
    "        ),\n",
    "        lataxis = dict (\n",
    "            showgrid = True,\n",
    "            gridwidth = 0.5,\n",
    "            range= [ 20.0, 60.0 ],\n",
    "            dtick = 5\n",
    "        )\n",
    "    ),\n",
    "    title='Top 2,500 locations with second mortgage is the highest and percent ownership is above 10 percent')\n",
    "fig.show()\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "    lat = df_train_location_mort_pct['lat'],\n",
    "    lon = df_train_location_mort_pct['lng']),\n",
    "    )\n",
    "fig.update_layout(\n",
    "    geo=dict(\n",
    "        scope = 'north america',\n",
    "        showland = True,\n",
    "        landcolor = \"rgb(212, 212, 212)\",\n",
    "        subunitcolor = \"rgb(255, 255, 255)\",\n",
    "        countrycolor = \"rgb(255, 255, 255)\",\n",
    "        showlakes = True,\n",
    "        lakecolor = \"rgb(255, 255, 255)\",\n",
    "        showsubunits = True,\n",
    "        showcountries = True,\n",
    "        resolution = 50,\n",
    "        projection = dict(\n",
    "            type = 'conic conformal',\n",
    "            rotation_lon = -100\n",
    "        ),\n",
    "        lonaxis = dict(\n",
    "            showgrid = True,\n",
    "            gridwidth = 0.5,\n",
    "            range= [ -140.0, -55.0 ],\n",
    "            dtick = 5\n",
    "        ),\n",
    "        lataxis = dict (\n",
    "            showgrid = True,\n",
    "            gridwidth = 0.5,\n",
    "            range= [ 20.0, 60.0 ],\n",
    "            dtick = 5\n",
    "        )\n",
    "    ),\n",
    "    title='Top 2,500 locations with second mortgage is the highest and percent ownership is above 10 percent')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following bad debt equation: Bad Debt = P (Second Mortgage ∩ Home Equity Loan) Bad Debt = second_mortgage + home_equity - home_equity_second_mortgage c) Create pie charts to show overall debt and bad debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bad_debt']=df_train['second_mortgage']+df_train['home_equity']-df_train['home_equity_second_mortgage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bins'] = pd.cut(df_train['bad_debt'],bins=[0,0.10,1], labels=[\"less than 50%\",\"50-100%\"])\n",
    "df_train.groupby(['bins']).size().plot(kind='pie',subplots=True,startangle=90, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()\n",
    "#df.plot.pie(subplots=True,figsize=(8, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Box and whisker plot and analyze the distribution for 2nd mortgage, home equity, good debt, and bad debt for different cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[]\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking Hamilton and Manhattan cities data\n",
    "cols=['second_mortgage','home_equity','debt','bad_debt']\n",
    "df_box_hamilton=df_train.loc[df_train['city'] == 'Hamilton']\n",
    "df_box_manhattan=df_train.loc[df_train['city'] == 'Manhattan']\n",
    "df_box_city=pd.concat([df_box_hamilton,df_box_manhattan])\n",
    "df_box_city.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df_box_city,x='second_mortgage', y='city',width=0.5,palette=\"Set3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df_box_city,x='home_equity', y='city',width=0.5,palette=\"Set3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df_box_city,x='debt', y='city',width=0.5,palette=\"Set3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df_box_city,x='bad_debt', y='city',width=0.5,palette=\"Set3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Manhattan has higher metrics compared to Hamilton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a collated income distribution chart for family income, house hold income, and remaining income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['hi_mean'])\n",
    "plt.title('Household income distribution chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['family_mean'])\n",
    "plt.title('Family income distribution chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['family_mean']-df_train['hi_mean'])\n",
    "plt.title('Remaining income distribution chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Income distribution almost has normality in its distrbution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform EDA and come out with insights into population density and age. You may have to derive new fields (make sure to weight averages for accurate measurements):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(3,1)\n",
    "sns.distplot(df_train['pop'],ax=ax1)\n",
    "sns.distplot(df_train['male_pop'],ax=ax2)\n",
    "sns.distplot(df_train['female_pop'],ax=ax3)\n",
    "plt.subplots_adjust(wspace=0.8,hspace=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(25,10))\n",
    "fig,(ax1,ax2)=plt.subplots(2,1)\n",
    "sns.distplot(df_train['male_age_mean'],ax=ax1)\n",
    "sns.distplot(df_train['female_age_mean'],ax=ax2)\n",
    "plt.subplots_adjust(wspace=0.8,hspace=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Use pop and ALand variables to create a new field called population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['pop_density']=df_train['pop']/df_train['ALand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['pop_density']=df_test['pop']/df_test['ALand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['pop_density'])\n",
    "plt.title('Population Density')\n",
    "plt.show() # Very less density is noticed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use male_age_median, female_age_median, male_pop, and female_pop to create a new field called median age \n",
    "### c) Visualize the findings using appropriate chart type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['age_median']=(df_train['male_age_median']+df_train['female_age_median'])/2\n",
    "df_test['age_median']=(df_test['male_age_median']+df_test['female_age_median'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['male_age_median','female_age_median','male_pop','female_pop','age_median']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['age_median'])\n",
    "plt.title('Median Age')\n",
    "plt.show()\n",
    "# Age of population is mostly between 20 and 60\n",
    "# Majority are of age around 40\n",
    "# Median age distribution has a gaussian distribution\n",
    "# Some right skewness is noticed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_train['age_median'])\n",
    "plt.title('Population Density')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bins for population into a new variable by selecting appropriate class interval so that the number of categories don’t exceed 5 for the ease of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['pop'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['pop_bins']=pd.cut(df_train['pop'],bins=5,labels=['very low','low','medium','high','very high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['pop','pop_bins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['pop_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the married, separated, and divorced population for these population brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby(by='pop_bins')[['married','separated','divorced']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby(by='pop_bins')[['married','separated','divorced']].agg([\"mean\", \"median\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Very high population group has more married people and less percantage of separated and divorced couples\n",
    "2. In very low population groups, there are more divorced people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize using appropriate chart type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "pop_bin_married=df_train.groupby(by='pop_bins')[['married','separated','divorced']].agg([\"mean\"])\n",
    "pop_bin_married.plot(figsize=(20,8))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please detail your observations for rent as a percentage of income at an overall level, and for different states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_state_mean=df_train.groupby(by='state')['rent_mean'].agg([\"mean\"])\n",
    "rent_state_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_state_mean=df_train.groupby(by='state')['family_mean'].agg([\"mean\"])\n",
    "income_state_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_perc_of_income=rent_state_mean['mean']/income_state_mean['mean']\n",
    "rent_perc_of_income.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall level rent as a percentage of income\n",
    "sum(df_train['rent_mean'])/sum(df_train['family_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform correlation analysis for all the relevant variables by creating a heatmap. Describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=df_train[['COUNTYID','STATEID','zip_code','type','pop', 'family_mean',\n",
    "         'second_mortgage', 'home_equity', 'debt','hs_degree',\n",
    "           'age_median','pct_own', 'married','separated', 'divorced']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(cor,annot=True,cmap='coolwarm')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. High positive correaltion is noticed between pop, male_pop and female_pop\n",
    "2. High positive correaltion is noticed between rent_mean,hi_mean, family_mean,hc_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. The economic multivariate data has a significant number of measured variables. The goal is to find where the measured variables depend on a number of smaller unobserved common factors or latent variables. 2. Each variable is assumed to be dependent upon a linear combination of the common factors, and the coefficients are known as loadings. Each measured variablealso includes a component due to independent random variability, known as “specific variance” because it is specific to one variable. Obtain the common factors and then plot the loadings. Use factor analysis to find latent variables in our dataset and gain insight into the linear relationships in the data. Following are the list of latent variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Highschool graduation rates • Median population age • Second mortgage statistics • Percent own • Bad debt expense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install factor_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa=FactorAnalyzer(n_factors=5)\n",
    "fa.fit_transform(df_train.select_dtypes(exclude= ('object','category')))\n",
    "fa.loadings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling : Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a linear Regression model to predict the total monthly expenditure for home mortgages loan. Please refer ‘deplotment_RE.xlsx’. Column hc_mortgage_mean is predicted variable. This is the mean monthly mortgage and owner costs of specified geographical location. Note: Exclude loans from prediction model which have NaN (Not a Number) values for hc_mortgage_mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['type'].unique()\n",
    "type_dict={'type':{'City':1, \n",
    "                   'Urban':2, \n",
    "                   'Town':3, \n",
    "                   'CDP':4, \n",
    "                   'Village':5, \n",
    "                   'Borough':6}\n",
    "          }\n",
    "df_train.replace(type_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.replace(type_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols=['COUNTYID','STATEID','zip_code','type','pop', 'family_mean',\n",
    "         'second_mortgage', 'home_equity', 'debt','hs_degree',\n",
    "           'age_median','pct_own', 'married','separated', 'divorced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df_train[feature_cols]\n",
    "y_train=df_train['hc_mortgage_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=df_test[feature_cols]\n",
    "y_test=df_test['hc_mortgage_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "x_train_scaled=sc.fit_transform(x_train)\n",
    "x_test_scaled=sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a model at a Nation level. If the accuracy levels and R square are not satisfactory proceed to below step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linereg=LinearRegression()\n",
    "linereg.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=linereg.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall R2 score of linear regression model\", r2_score(y_test,y_pred))\n",
    "print(\"Overall RMSE of linear regression model\", np.sqrt(mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy and R2 score are good, but still will investigate the model performance at state level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run another model at State level. There are 52 states in USA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=df_train['STATEID'].unique()\n",
    "state[0:5]\n",
    "#Picking a few iDs 20,1,45,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [20,1,45]:\n",
    "    print(\"State ID-\",i)\n",
    "    \n",
    "    x_train_nation=df_train[df_train['COUNTYID']==i][feature_cols]\n",
    "    y_train_nation=df_train[df_train['COUNTYID']==i]['hc_mortgage_mean']\n",
    "    \n",
    "    x_test_nation=df_test[df_test['COUNTYID']==i][feature_cols]\n",
    "    y_test_nation=df_test[df_test['COUNTYID']==i]['hc_mortgage_mean']\n",
    "    \n",
    "    x_train_scaled_nation=sc.fit_transform(x_train_nation)\n",
    "    x_test_scaled_nation=sc.fit_transform(x_test_nation)\n",
    "    \n",
    "    linereg.fit(x_train_scaled_nation,y_train_nation)\n",
    "    y_pred_nation=linereg.predict(x_test_scaled_nation)\n",
    "    \n",
    "    print(\"Overall R2 score of linear regression model for state,\",i,\":-\" ,r2_score(y_test_nation,y_pred_nation))\n",
    "    print(\"Overall RMSE of linear regression model for state,\",i,\":-\" ,np.sqrt(mean_squared_error(y_test_nation,y_pred_nation)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals=y_test-y_pred\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals) # Normal distribution of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(residuals,y_pred) # Same variance and residuals does not have correlation with predictor\n",
    "# Independance of residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ------THANK YOU------ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
